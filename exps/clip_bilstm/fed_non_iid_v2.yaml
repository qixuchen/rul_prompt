# all 
# 0.001 Test_RMSE_cor = 16.14920, Test_RULscore_min = 3181.57699

# partial 
# 0.001 0.2 250 400 Test_RMSE_cor = 17.44197, Test_RULscore_min = 3681.50152
# 0.0005 0.2 250 400 Test_RMSE_cor = 16.42387, Test_RULscore_min = 3429.18983
# 0.0005 0.2 400 500 Test_RMSE_cor = 16.27049, Test_RULscore_min = 3332.68369
# 0.0005 0.2 400 600 Test_RMSE_cor = 16.32981, Test_RULscore_min = 3302.73304

# no alignment
# Test_RMSE_cor = 16.32557, Test_RULscore_min = 3412.89805
---
gpu: '0'
save_frequency: 5
seed: 3000
task: 't1'

dist_backend: 'nccl'
world_size: -1
rank: -1
dist_url: 'tcp://224.66.41.62:23456'
multiprocessing_distributed: False
distributed: False
#dataset
data:
  root: './data'
  set: 'FD001'
  max_rul: 125
  seq_len: 30 
  num_worker: 4

#network
net:
  name: 'bilstm_clip'
  hand_craft: False
  input_dim: 14
  aux_dim: 4
  num_hidden: 18
  hand_dim: 28

# #fedrated learning
# fed:
#   n_user: 5
#   n_user_per_iter: 2
#   sample_interval: 1
#   iid: 'non_iid_v2'

# #train
# train:
#   resume_epoch: 0
#   batch_size: 128
#   lr: 0.001
#   optimizer: 'adam'
#   lr_epoch: [300]
#   lr_factor: 0.1
#   end_epoch: 500
#   callback_freq: 50
#   warmup_iters: 0

#fedrated learning
fed:
  n_user: 5
  n_user_per_iter: 5
  train_epoch_per_step: 2
  sample_interval: 1
  iid: 'non_iid_v2'

#train
train:
  resume_epoch: 0
  batch_size: 128
  lr: 0.001
  optimizer: 'adam'
  lr_epoch: [250]
  lr_factor: 0.2
  end_epoch: 400
  callback_freq: 50
  warmup_iters: 0

# test
test:
  model_name: 'exp_202110121100_cnn_pe_ep-0050.pth'
  model_path: './output/basic/FD_noniid'
  test_freq: 1